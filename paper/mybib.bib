
@misc{CWE-89,
  author = "{MITRE Corporation}",
  title = "{Common Weakness Enumeration}: CWE-89: Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection')",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/89.html}",
  year = {2021},
  note = "[Accessed: March 14, 2023]"
}

@misc{CWE-77,
  author = "{MITRE Corporation}",
  title = "{Common Weakness Enumeration}: CWE-77: Improper Neutralization of Special Elements used in a Command ('Command Injection')",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/77.html}",
  year = {2021},
  note = "[Accessed: March 14, 2023]"
}

@misc{cwe22,
  title = "{CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')}",
  author = "{Common Weakness Enumeration}",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/22.html}",
  year = {n.d.},
  note = {Accessed: March 14, 2023}
}
@misc{cwe94,
  title = "{CWE-94: Improper Control of Generation of Code ('Code Injection')}",
  author = "{Common Weakness Enumeration}",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/94.html}",
  year = {n.d.},
  note = {Accessed: March 14, 2023}
}

@misc{cwe79,
  title = "{CWE-79: Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')}",
  author = "{Common Weakness Enumeration}",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/79.html}",
  year = {n.d.},
  note = {Accessed: March 14, 2023}
}

@misc{cwe352,
  title = "{CWE-352: Cross-Site Request Forgery (CSRF)}",
  author = "{Common Weakness Enumeration}",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/352.html}",
  year = {n.d.},
  note = {Accessed: March 14, 2023}
}

@misc{cwe601,
  title = "{CWE-601: URL Redirection to Untrusted Site ('Open Redirect')}",
  author = "{Common Weakness Enumeration}",
  howpublished = "\url{https://cwe.mitre.org/data/definitions/601.html}",
  year = {n.d.},
  note = {Accessed: March 14, 2023}
}


@online{codegrip,
  author = {CodeGrip},
  title = {What is Code Vulnerability?},
  year = {2021},
  url = {https://www.codegrip.tech/productivity/what-is-code-vulnerability/},
  urldate = {2023-03-09}
}

@misc{perceiver,
  doi = {10.48550/ARXIV.2103.03206},
  url = {https://arxiv.org/abs/2103.03206},
  author = {Jaegle,  Andrew and Gimeno,  Felix and Brock,  Andrew and Zisserman,  Andrew and Vinyals,  Oriol and Carreira,  Joao},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  Sound (cs.SD),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Perceiver: General Perception with Iterative Attention},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{sast_tools_study,
title = {An empirical study of security warnings from static application security testing tools},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110427},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110427},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302018},
author = {Bushra Aloraini and Meiyappan Nagappan and Daniel M. German and Shinpei Hayashi and Yoshiki Higo},
keywords = {False positives, Security warnings, Software vulnerability, Static application security testing tools},
abstract = {The Open Web Application Security Project (OWASP) defines Static Application Security Testing (SAST) tools as those that can help find security vulnerabilities in the source code or compiled code of the software. Such tools detect and classify vulnerability warnings into one of many types (e.g., input validation and representation). It is well known that these tools produce high numbers of false positive warnings. However, what is not known is if specific types of warnings have a higher predisposition to be false positives or not. Therefore, our goal is to investigate the different types of SAST-produced warnings and their evolution over time to determine if one type of warning is more likely to have false positives than others. To achieve our goal, we carry out a large empirical study where we examine 116 large and popular C++ projects using six different state-of-the-art open-source and commercial SAST tools that detect security vulnerabilities. In order to track a piece of code that has been tagged with a warning, we use a new state-of-the-art framework called cregit+ that traces source code lines across different commits. The results demonstrate the potential of using SAST tools as an assessment tool to measure the quality of a product and the possible risks without manually reviewing the warnings. In addition, this work shows that the pattern-matching static analysis technique is a very powerful method when combined with other advanced analysis methods.}
}
@misc{Wiki:sast,
  title = {Static application security testing},
  howpublished = {\url{https://en.wikipedia.org/wiki/Static_application_security_testing}},
}
@misc{pattern_tool1,
  title = {Brakeman: Ruby on Rails Static Analysis Security Tool},
  howpublished = {\url{https://brakemanscanner.org/}},
}
@misc{pattern_tool2,
  title = {Findbugs - Static Code Analysis of Java},
  howpublished = {\url{https://www.methodsandtools.com/tools/findbugs.php}},
  note = {Accessed: March 8, 2023}
}
@misc{pattern_tool3,
  title = {RIPS - A static source code analyser for vulnerabilities in PHP scripts},
  howpublished = {\url{https://rips-scanner.sourceforge.net/}},
  note = {Accessed: March 8, 2023}
}
@misc{rule_tool1,
  title = {SonarQube Documentation},
  howpublished = {\url{https://docs.sonarqube.org/}},
  note = {Accessed: March 8, 2023}
}
@misc{rule_tool2,
  title = {Eslint:Find and fix problems in your JavaScript code},
  howpublished = {\url{https://eslint.org/}},
  note = {Accessed: March 8, 2023}
}
@misc{rule_tool3,
  title = {PMD:An extensible cross-language static code analyzer},
  howpublished = {\url{https://pmd.github.io/}},
  note = {Accessed: March 8, 2023}
}
@misc{rule_tool4,
  title = {Bandit: Security linter for Python},
  howpublished = {\url{https://github.com/PyCQA/bandit}},
  year = {2023},
  note = {Accessed: March 8, 2023}
}
@manual{rule_tool6,
  title = {Flawfinder},
  author = {Wheeler, David A.},
  howpublished = {\url{https://dwheeler.com/flawfinder/}},
  year = {2023},
  note = {Accessed: March 8, 2023}
}
@misc{coverity,
  title = {Coverity},
  howpublished = {\url{https://scan.coverity.com/}},
  year = {2023},
  note = {Accessed: March 8, 2023}
}
@misc{rule_tool5,
  title = {Pylint},
  howpublished = {\url{https://pypi.org/project/pylint/}},
  year = {2023},
  note = {Accessed on March 8, 2023}
}
@misc{pattern_tool4,
  title = {{Semgrep: A Fast, Modern Pattern Matcher for Source Code}},
  author = {{r2c}},
  howpublished = {\url{https://semgrep.dev/}},
  year = {2021},
  note = {Accessed: March 8, 2023}
}
@manual{pattern_tool5,
  title = {{CodeQL}},
  author = {{GitHub, Inc.}},
  organization = {{GitHub}},
  address = {San Francisco, CA},
  year = {2021},
  note = {Accessed: March 8, 2023}
}
@inproceedings{cvefixes,
    title = {{CVEfixes: Automated Collection of Vulnerabilities  and Their Fixes from Open-Source Software}},
    booktitle = {{Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE '21)}},
    author = {Bhandari, Guru and Naseer, Amara and Moonen, Leon},
    year = {2021},
    pages = {10},
    publisher = {{ACM}},
    doi = {10.1145/3475960.3475985},
    copyright = {Open Access},
    isbn = {978-1-4503-8680-7},
    language = {en}
}
@article{Vudenc,
  doi = {10.48550/ARXIV.2201.08441},
  url = {https://arxiv.org/abs/2201.08441},
  author = {Wartschinski,  Laura and Noller,  Yannic and Vogel,  Thomas and Kehrer,  Timo and Grunske,  Lars},
  keywords = {Cryptography and Security (cs.CR),  Machine Learning (cs.LG),  Software Engineering (cs.SE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
@misc{Draper,
  doi = {10.48550/ARXIV.1807.04320},
  url = {https://arxiv.org/abs/1807.04320},
  author = {Russell,  Rebecca L. and Kim,  Louis and Hamilton,  Lei H. and Lazovich,  Tomo and Harer,  Jacob A. and Ozdemir,  Onur and Ellingwood,  Paul M. and McConley,  Marc W.},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Software Engineering (cs.SE),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Automated Vulnerability Detection in Source Code Using Deep Representation Learning},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{transformer2graph,
  author = {Chaitanya K. Joshi},
  title = {Transformers are
Graph Neural Networks},
  note = {Accessed: March 8, 2023}
  url = {https://graphdeeplearning.github.io/files/transformers-are-gnns-slides.pdf},
}
@misc{nvd,
  title = {{National Vulnerability Database}},
  author = {{National Institute of Standards and Technology}},
  howpublished = {\url{https://nvd.nist.gov/}},
  note = {Accessed: March 8, 2023}
}
@misc{Are,
  doi = {10.48550/ARXIV.2009.07235},
  url = {https://arxiv.org/abs/2009.07235},
  author = {Chakraborty,  Saikat and Krishna,  Rahul and Ding,  Yangruibo and Ray,  Baishakhi},
  keywords = {Software Engineering (cs.SE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Deep Learning based Vulnerability Detection: Are We There Yet?},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{LineVD,
  doi = {10.48550/ARXIV.2203.05181},
  url = {https://arxiv.org/abs/2203.05181},
  author = {Hin,  David and Kan,  Andrey and Chen,  Huaming and Babar,  M. Ali},
  keywords = {Cryptography and Security (cs.CR),  Software Engineering (cs.SE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {LineVD: Statement-level Vulnerability Detection using Graph Neural Networks},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{GAT,
  doi = {10.48550/ARXIV.1710.10903},
  url = {https://arxiv.org/abs/1710.10903},
  author = {Veličković,  Petar and Cucurull,  Guillem and Casanova,  Arantxa and Romero,  Adriana and Liò,  Pietro and Bengio,  Yoshua},
  keywords = {Machine Learning (stat.ML),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  Social and Information Networks (cs.SI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Graph Attention Networks},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{GCN,
  doi = {10.48550/ARXIV.1609.02907},
  url = {https://arxiv.org/abs/1609.02907},
  author = {Kipf,  Thomas N. and Welling,  Max},
  keywords = {Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Semi-Supervised Classification with Graph Convolutional Networks},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{devign,
  doi = {10.48550/ARXIV.1909.03496},
  url = {https://arxiv.org/abs/1909.03496},
  author = {Zhou,  Yaqin and Liu,  Shangqing and Siow,  Jingkai and Du,  Xiaoning and Liu,  Yang},
  keywords = {Software Engineering (cs.SE),  Cryptography and Security (cs.CR),  Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@incollection{Embeds_comparison,
  doi = {10.1007/978-3-030-85347-1_20},
  url = {https://doi.org/10.1007/978-3-030-85347-1_20},
  year = {2021},
  publisher = {Springer International Publishing},
  pages = {267--281},
  author = {f Bagheri and P{\'{e}}ter Heged{\H{u}}s},
  title = {A Comparison of Different Source Code Representation Methods for Vulnerability Prediction in Python},
  booktitle = {Communications in Computer and Information Science}
}
@misc{func_level_4,
  doi = {10.48550/ARXIV.1807.04320},
  url = {https://arxiv.org/abs/1807.04320},
  author = {Russell,  Rebecca L. and Kim,  Louis and Hamilton,  Lei H. and Lazovich,  Tomo and Harer,  Jacob A. and Ozdemir,  Onur and Ellingwood,  Paul M. and McConley,  Marc W.},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Software Engineering (cs.SE),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Automated Vulnerability Detection in Source Code Using Deep Representation Learnings},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@INPROCEEDINGS{File_level_1,
  author={Pang, Yulei and Xue, Xiaozhen and Namin, Akbar Siami},
  booktitle={2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Predicting Vulnerable Software Components through N-Gram Analysis and Statistical Feature Selection}, 
  year={2015},
  volume={},
  number={},
  pages={543-548},
  doi={10.1109/ICMLA.2015.99}
}
@ARTICLE{File_level_2,
  author={Dam, Hoa Khanh and Tran, Truyen and Pham, Trang and Ng, Shien Wee and Grundy, John and Ghose, Aditya},
  journal={IEEE Transactions on Software Engineering}, 
  title={Automatic Feature Learning for Predicting Vulnerable Software Components}, 
  year={2021},
  volume={47},
  number={1},
  pages={67-85},
  doi={10.1109/TSE.2018.2881961}
}
@inproceedings{File_level_3,
author = {Hovsepyan, Aram and Scandariato, Riccardo and Joosen, Wouter and Walden, James},
title = {Software Vulnerability Prediction Using Text Analysis Techniques},
year = {2012},
isbn = {9781450315081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2372225.2372230},
doi = {10.1145/2372225.2372230},
abstract = {Early identification of software vulnerabilities is essential in software engineering and can help reduce not only costs, but also prevent loss of reputation and damaging litigations for a software firm. Techniques and tools for software vulnerability prediction are thus invaluable. Most of the existing techniques rely on using component characteristic(s) (like code complexity, code churn) for the vulnerability prediction. In this position paper, we present a novel approach for vulnerability prediction that leverages on the analysis of raw source code as text, instead of using "cooked" features. Our initial results seem to be very promising as the prediction model achieves an average accuracy of 0.87, precision of 0.85 and recall of 0.88 on 18 versions of a large mobile application.},
booktitle = {Proceedings of the 4th International Workshop on Security Measurements and Metrics},
pages = {7–10},
numpages = {4},
keywords = {text analysis, machine learning, vulnerability prediction},
location = {Lund, Sweden},
series = {MetriSec '12}
}
@article{func_level_1,
  doi = {10.48550/ARXIV.2106.10478},
  url = {https://arxiv.org/abs/2106.10478},
  author = {Li,  Yi and Wang,  Shaohua and Nguyen,  Tien N.},
  keywords = {Cryptography and Security (cs.CR),  Software Engineering (cs.SE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Vulnerability Detection with Fine-grained Interpretations},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{func_level_2,
  doi = {10.1016/j.infsof.2021.106576},
  url = {https://doi.org/10.1016/j.infsof.2021.106576},
  year = {2021},
  month = aug,
  publisher = {Elsevier {BV}},
  volume = {136},
  pages = {106576},
  author = {Sicong Cao and Xiaobing Sun and Lili Bo and Ying Wei and Bin Li},
  title = {{BGNN}4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection},
  journal = {Information and Software Technology}
}
@article{VulDeeLocator,
  doi = {10.48550/ARXIV.2001.02350},
  url = {https://arxiv.org/abs/2001.02350},
  author = {Li,  Zhen and Zou,  Deqing and Xu,  Shouhuai and Chen,  Zhaoxuan and Zhu,  Yawei and Jin,  Hai},
  keywords = {Cryptography and Security (cs.CR),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {VulDeeLocator: A Deep Learning-based Fine-grained Vulnerability Detector},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{SySeVR,
  doi = {10.48550/ARXIV.1807.06756},
  url = {https://arxiv.org/abs/1807.06756},
  author = {Li,  Zhen and Zou,  Deqing and Xu,  Shouhuai and Jin,  Hai and Zhu,  Yawei and Chen,  Zhaoxuan},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Cryptography and Security (cs.CR),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{vuldeekeeper,
  doi = {10.48550/ARXIV.1801.01681},
  url = {https://arxiv.org/abs/1801.01681},
  author = {Li,  Zhen and Zou,  Deqing and Xu,  Shouhuai and Ou,  Xinyu and Jin,  Hai and Wang,  Sujuan and Deng,  Zhijun and Zhong,  Yuyi},
  keywords = {Cryptography and Security (cs.CR),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {VulDeePecker: A Deep Learning-Based System for Vulnerability Detection},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@inproceedings{file_level_4,
author = {Hovsepyan, Aram and Scandariato, Riccardo and Joosen, Wouter},
title = {Is Newer Always Better? The Case of Vulnerability Prediction Models},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962612},
doi = {10.1145/2961111.2962612},
abstract = {Finding security vulnerabilities in the source code as early as possible is becoming more and more essential. In this respect, vulnerability prediction models have the potential to help the security assurance activities by identifying code locations that deserve the most attention. In this paper, we investigate whether prediction models behave like milk (i.e., they turn with time) or wine (i.e., the improve with time) when used to predict future vulnerabilities. Our findings indicate that the recall values are largely in favor of predictors based on older versions. However, the better recall comes at the price of much higher file inspection ratio values.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {26},
numpages = {6},
keywords = {prediction models, Security vulnerabilities},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}
@ARTICLE{survey_1,
  author={Lin, Guanjun and Wen, Sheng and Han, Qing-Long and Zhang, Jun and Xiang, Yang},
  journal={Proceedings of the IEEE}, 
  title={Software Vulnerability Detection Using Deep Neural Networks: A Survey}, 
  year={2020},
  volume={108},
  number={10},
  pages={1825-1848},
  doi={10.1109/JPROC.2020.2993293}}
@misc{BERT,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin,  Jacob and Chang,  Ming-Wei and Lee,  Kenton and Toutanova,  Kristina},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{attention,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani,  Ashish and Shazeer,  Noam and Parmar,  Niki and Uszkoreit,  Jakob and Jones,  Llion and Gomez,  Aidan N. and Kaiser,  Lukasz and Polosukhin,  Illia},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{LSTM,
author = {Sak, H. and Senior, Andrew and Beaufays, F.},
year = {2014},
month = {01},
pages = {338-342},
title = {Long short-term memory recurrent neural network architectures for large scale acoustic modeling},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH}
}
@misc{GRU,
  doi = {10.48550/ARXIV.1409.1259},
  url = {https://arxiv.org/abs/1409.1259},
  author = {Cho,  Kyunghyun and van Merrienboer,  Bart and Bahdanau,  Dzmitry and Bengio,  Yoshua},
  keywords = {Computation and Language (cs.CL),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {On the Properties of Neural Machine Translation: Encoder-Decoder Approaches},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{word2vec,
  doi = {10.48550/ARXIV.1301.3781},
  url = {https://arxiv.org/abs/1301.3781},
  author = {Mikolov,  Tomas and Chen,  Kai and Corrado,  Greg and Dean,  Jeffrey},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{MVD,
  doi = {10.48550/ARXIV.2203.02660},
  url = {https://arxiv.org/abs/2203.02660},
  author = {Cao,  Sicong and Sun,  Xiaobing and Bo,  Lili and Wu,  Rongxin and Li,  Bin and Tao,  Chuanqi},
  keywords = {Cryptography and Security (cs.CR),  Software Engineering (cs.SE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{semi-synthesis-dataset1,
  doi = {10.48550/ARXIV.1807.04320},
  url = {https://arxiv.org/abs/1807.04320},
  author = {Russell,  Rebecca L. and Kim,  Louis and Hamilton,  Lei H. and Lazovich,  Tomo and Harer,  Jacob A. and Ozdemir,  Onur and Ellingwood,  Paul M. and McConley,  Marc W.},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Software Engineering (cs.SE),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Automated Vulnerability Detection in Source Code Using Deep Representation Learning},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@techreport{SATE,
  doi = {10.6028/nist.sp.500-297},
  url = {https://doi.org/10.6028/nist.sp.500-297},
  year = {2013},
  month = jan,
  publisher = {National Institute of Standards and Technology},
  author = {Vadim Okun and Aurelien Delaitre and Paul E. Black},
  title = {Report on the Static Analysis Tool Exposition ({SATE}) {IV}}
}
@article{sard,
  doi = {10.6028/jres.123.005},
  url = {https://doi.org/10.6028/jres.123.005},
  year = {2018},
  month = apr,
  publisher = {National Institute of Standards and Technology ({NIST})},
  volume = {123},
  author = {Paul E. Black},
  title = {A Software Assurance Reference Dataset: Thousands of Programs With Known Bugs},
  journal = {Journal of Research of the National Institute of Standards and Technology}
}
@misc{GNN,
  doi = {10.48550/ARXIV.2209.13232},
  url = {https://arxiv.org/abs/2209.13232},
  author = {Chen,  Chaoqi and Wu,  Yushuang and Dai,  Qiyuan and Zhou,  Hong-Yu and Xu,  Mutian and Yang,  Sibei and Han,  Xiaoguang and Yu,  Yizhou},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@INPROCEEDINGS{c_tool1,
  author={Lattner, C. and Adve, V.},
  booktitle={International Symposium on Code Generation and Optimization, 2004. CGO 2004.}, 
  title={LLVM: a compilation framework for lifelong program analysis & transformation}, 
  year={2004},
  volume={},
  number={},
  pages={75-86},
  doi={10.1109/CGO.2004.1281665}
  }
@inproceedings{c_tool2,
author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
title = {KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs},
year = {2008},
publisher = {USENIX Association},
address = {USA},
abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, the results were even better, including 100\% coverage on 31 of them. We also used KLEE as a bug-finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},
pages = {209–224},
numpages = {16},
location = {San Diego, California},
series = {OSDI'08}
}
@book{ctool3,
author = {Eagle, Chris},
title = {The IDA Pro Book: The Unofficial Guide to the World's Most Popular Disassembler},
year = {2011},
isbn = {1593272898},
publisher = {No Starch Press},
address = {USA},
abstract = {No source code? No problem. With IDA Pro, the interactive disassembler, you live in a source code-optional world. IDA can automatically analyze the millions of opcodes that make up an executable and present you with a disassembly. But at that point, your work is just beginning. With The IDA Pro Book, you'll learn how to turn that mountain of mnemonics into something you can actually use.Hailed by the creator of IDA Pro as "profound, comprehensive, and accurate," the second edition of The IDA Pro Book covers everything from the very first steps to advanced automation techniques. You'll find complete coverage of IDA's new Qt-based user interface, as well as increased coverage of the IDA debugger, the Bochs debugger, and IDA scripting (especially using IDAPython). But because humans are still smarter than computers, you'll even learn how to use IDA's latest interactive and scriptable interfaces to your advantage.Save time and effort as you learn to: Navigate, comment, and modify disassembly Identify known library routines, so you can focus your analysis on other areas of the code Use code graphing to quickly make sense of cross references and function calls Extend IDA to support new processors and filetypes using the SDK Explore popular plug-ins that make writing IDA scripts easier, allow collaborative reverse engineering, and much more Use IDA's built-in debugger to tackle hostile and obfuscated code Whether you're analyzing malware, conducting vulnerability research, or reverse engineering software, a mastery of IDA is crucial to your success. Take your skills to the next level with this 2nd edition of The IDA Pro Book.}
}
@misc{ctool4,
  organization = {GNU},
  title = {15 Control Flow Graph},
  url = {https://gcc.gnu.org/onlinedocs/gccint/Control-Flow.html},
  note = {Accessed: 8th February 2023}
}
@inproceedings{IVDetect,
author = {Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
title = {Vulnerability Detection with Fine-Grained Interpretations},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468597},
doi = {10.1145/3468264.3468597},
abstract = {Despite the successes of machine learning (ML) and deep learning (DL)-based vulnerability detectors (VD), they are limited to providing only the decision on whether a given code is vulnerable or not, without details on what part of the code is relevant to the detected vulnerability. We present IVDetect, an interpretable vulnerability detector with the philosophy of using Artificial Intelligence (AI) to detect vulnerabilities, while using Intelligence Assistant (IA) to provide VD interpretations in terms of vulnerable statements. For vulnerability detection, we separately consider the vulnerable statements and their surrounding contexts via data and control dependencies. This allows our model better discriminate vulnerable statements than using the mixture of vulnerable code and contextual code as in existing approaches. In addition to the coarse-grained vulnerability detection result, we leverage interpretable AI to provide users with fine-grained interpretations that include the sub-graph in the Program Dependency Graph (PDG) with the crucial statements that are relevant to the detected vulnerability. Our empirical evaluation on vulnerability databases shows that IVDetect outperforms the existing DL-based approaches by 43\%–84\% and 105\%–255\% in top-10 nDCG and MAP ranking scores. IVDetect correctly points out the vulnerable statements relevant to the vulnerability via its interpretation in 67\% of the cases with a top-5 ranked list. IVDetect improves over the baseline interpretation models by 12.3\%–400\% and 9\%–400\% in accuracy.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {292–303},
numpages = {12},
keywords = {Vulnerability Detection, Deep Learning, Interpretable AI, Intelligence Assistant, Explainable AI (XAI)},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}
@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}
@misc{doc2vec,
  doi = {10.48550/ARXIV.1405.4053},
  url = {https://arxiv.org/abs/1405.4053},
  author = {Le,  Quoc V. and Mikolov,  Tomas},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Distributed Representations of Sentences and Documents},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{DeepWukong,
author = {Cheng, Xiao and Wang, Haoyu and Hua, Jiayi and Xu, Guoai and Sui, Yulei},
title = {DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3436877},
doi = {10.1145/3436877},
abstract = {Static bug detection has shown its effectiveness in detecting well-defined memory errors, e.g., memory leaks, buffer overflows, and null dereference. However, modern software systems have a wide variety of vulnerabilities. These vulnerabilities are extremely complicated with sophisticated programming logic, and these bugs are often caused by different bad programming practices, challenging existing bug detection solutions. It is hard and labor-intensive to develop precise and efficient static analysis solutions for different types of vulnerabilities, particularly for those that may not have a clear specification as the traditional well-defined vulnerabilities.This article presents DeepWukong, a new deep-learning-based embedding approach to static detection of software vulnerabilities for C/C++ programs. Our approach makes a new attempt by leveraging advanced recent graph neural networks to embed code fragments in a compact and low-dimensional representation, producing a new code representation that preserves high-level programming logic (in the form of control- and data-flows) together with the natural language information of a program. Our evaluation studies the top 10 most common C/C++ vulnerabilities during the past 3 years. We have conducted our experiments using 105,428 real-world programs by comparing our approach with four well-known traditional static vulnerability detectors and three state-of-the-art deep-learning-based approaches. The experimental results demonstrate the effectiveness of our research and have shed light on the promising direction of combining program analysis with deep learning techniques to address the general static code analysis challenges.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {38},
numpages = {33},
keywords = {vulnerabilities, Static analysis, graph embedding}
}
@article{vuldeepeeker2,
  doi = {10.1109/tdsc.2019.2942930},
  url = {https://doi.org/10.1109/tdsc.2019.2942930},
  year = {2019},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Deqing Zou and Sujuan Wang and Shouhuai Xu and Zhen Li and Hai Jin},
  title = {$\upmu${VulDeePecker}: A Deep Learning-Based System for Multiclass Vulnerability Detection},
  journal = {{IEEE} Transactions on Dependable and Secure Computing}
}
@misc{devsecop,
  author = {KEV ZETTLER},
  title = {devsecops tools},
  note = {Accessed: March 8, 2023},
  url = {https://www.atlassian.com/devops/devops-tools/devsecops-tools},
}
@misc{sast_sample,
  author = {KEV ZETTLER},
  title = {SAST},
  year = {Year},
  url={https://cssa.cc.ncku.edu.tw/gitlab/help/user/application_security/sast/index.md},
  note = {Accessed: March 8, 2023}
}
@misc{Dynamic_embeddings,
author = {Xu, Chenxin and Wei, Yuxi and Tang, Bohan and Yin, Sheng and Zhang, Ya and Chen, Siheng},
year = {2022},
month = {06},
pages = {},
title = {Dynamic-Group-Aware Networks for Multi-Agent Trajectory Prediction with Relational Reasoning},
doi = {10.48550/arXiv.2206.13114}
}
@misc{gnnarchitectures,
author = {Jin, Zhihua and Wang, Yong and Wang, Qianwen and Ming, Yao and Ma, Tengfei and Qu, Huamin},
year = {2020},
month = {11},
pages = {},
title = {GNNVis: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks}
}
@article{GGNN,
  doi = {10.48550/ARXIV.2002.01038},
  url = {https://arxiv.org/abs/2002.01038},
  author = {Ruiz,  Luana and Gama,  Fernando and Ribeiro,  Alejandro},
  keywords = {Signal Processing (eess.SP),  Machine Learning (cs.LG),  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Gated Graph Recurrent Neural Networks},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{GNExplainer,
  doi = {10.48550/ARXIV.1903.03894},
  url = {https://arxiv.org/abs/1903.03894},
  author = {Ying,  Rex and Bourgeois,  Dylan and You,  Jiaxuan and Zitnik,  Marinka and Leskovec,  Jure},
  keywords = {Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {GNNExplainer: Generating Explanations for Graph Neural Networks},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{codeBERT,
  doi = {10.48550/ARXIV.2002.08155},
  url = {https://arxiv.org/abs/2002.08155},
  author = {Feng,  Zhangyin and Guo,  Daya and Tang,  Duyu and Duan,  Nan and Feng,  Xiaocheng and Gong,  Ming and Shou,  Linjun and Qin,  Bing and Liu,  Ting and Jiang,  Daxin and Zhou,  Ming},
  keywords = {Computation and Language (cs.CL),  Programming Languages (cs.PL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {CodeBERT: A Pre-Trained Model for Programming and Natural Languages},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@inproceedings{sBERT,
    title = "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2004.09813",
}
@article{mpnet,
    title={MPNet: Masked and Permuted Pre-training for Language Understanding},
    author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
    journal={arXiv preprint arXiv:2004.09297},
    year={2020}
}
@misc{minilm,
  doi = {10.48550/ARXIV.2002.10957},
  url = {https://arxiv.org/abs/2002.10957},
  author = {Wang,  Wenhui and Wei,  Furu and Dong,  Li and Bao,  Hangbo and Yang,  Nan and Zhou,  Ming},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{activation,
  doi = {10.48550/ARXIV.2109.14545},
  url = {https://arxiv.org/abs/2109.14545},
  author = {Dubey,  Shiv Ram and Singh,  Satish Kumar and Chaudhuri,  Bidyut Baran},
  keywords = {Machine Learning (cs.LG),  Neural and Evolutionary Computing (cs.NE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Activation Functions in Deep Learning: A Comprehensive Survey and Benchmark},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{fasttext,
  title={FastText.zip: Compressing text classification models},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\'e}gou, H{\'e}rve and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1612.03651},
  year={2016}
}
@misc{layer_norm,
  doi = {10.48550/ARXIV.1607.06450},
  url = {https://arxiv.org/abs/1607.06450},
  author = {Ba,  Jimmy Lei and Kiros,  Jamie Ryan and Hinton,  Geoffrey E.},
  keywords = {Machine Learning (stat.ML),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Layer Normalization},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}


@misc{batch_norm,
  doi = {10.48550/ARXIV.1502.03167},
  url = {https://arxiv.org/abs/1502.03167},
  author = {Ioffe,  Sergey and Szegedy,  Christian},
  keywords = {Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{message_passing,
  doi = {10.1016/j.neunet.2021.02.025},
  url = {https://doi.org/10.1016/j.neunet.2021.02.025},
  year = {2021},
  month = aug,
  publisher = {Elsevier {BV}},
  volume = {140},
  pages = {130--135},
  author = {Xue Li and Yuanzhi Cheng},
  title = {Understanding the message passing in graph neural networks via power iteration clustering},
  journal = {Neural Networks}
}

@misc{adamW,
  doi = {10.48550/ARXIV.1711.05101},
  url = {https://arxiv.org/abs/1711.05101},
  author = {Loshchilov,  Ilya and Hutter,  Frank},
  keywords = {Machine Learning (cs.LG),  Neural and Evolutionary Computing (cs.NE),  Optimization and Control (math.OC),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Mathematics,  FOS: Mathematics},
  title = {Decoupled Weight Decay Regularization},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}


@misc{nltk,
  title={Natural Language Toolkit},
  author={Bird, Steven and Loper, Edward and Klein, Ewan},
  year={2009},
  publisher={ACM},
  howpublished={\url{https://www.nltk.org/}}
}

@misc{bpe,
  doi = {10.48550/ARXIV.1508.07909},
  url = {https://arxiv.org/abs/1508.07909},
  author = {Sennrich,  Rico and Haddow,  Barry and Birch,  Alexandra},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Neural Machine Translation of Rare Words with Subword Units},
  publisher = {arXiv},
  year = {2015},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{sentencepiece,
  doi = {10.48550/ARXIV.1808.06226},
  url = {https://arxiv.org/abs/1808.06226},
  author = {Kudo,  Taku and Richardson,  John},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{wordpiece,
  doi = {10.48550/ARXIV.2012.15524},
  url = {https://arxiv.org/abs/2012.15524},
  author = {Song,  Xinying and Salcianu,  Alex and Song,  Yang and Dopson,  Dave and Zhou,  Denny},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Fast WordPiece Tokenization},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{pretrain_survey,
  doi = {10.48550/ARXIV.2003.08271},
  url = {https://arxiv.org/abs/2003.08271},
  author = {Qiu,  Xipeng and Sun,  Tianxiang and Xu,  Yige and Shao,  Yunfan and Dai,  Ning and Huang,  Xuanjing},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Pre-trained Models for Natural Language Processing: A Survey},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{DAST5,
  title={Burp Suite},
  author={PortSwigger},
  year={2021},
  publisher={PortSwigger Ltd.},
  howpublished={\url{https://portswigger.net/burp}}
}
@misc{DAST4,
  title={OWASP ZAP},
  author={The OWASP ZAP Team},
  year={2021},
  publisher={OWASP Foundation},
  howpublished={\url{https://owasp.org/www-project-zap/}}
}
@misc{DAST3,
  title={Acunetix},
  author={Acunetix Ltd.},
  year={2021},
  publisher={Acunetix Ltd.},
  howpublished={\url{https://www.acunetix.com/}}
}
@misc{DAST2,
  title={Netsparker},
  author={Netsparker Ltd.},
  year={2021},
  publisher={Netsparker Ltd.},
  howpublished={\url{https://www.netsparker.com/}}
}

@misc{DAST1,
  title={Qualys Web Application Scanning (WAS)},
  author={Qualys, Inc.},
  year={2021},
  publisher={Qualys, Inc.},
  howpublished={\url{https://www.qualys.com/apps/web-app-scanning/}}
}
@misc{RASP1,
  title={AppArmor},
  author={Canonical Ltd.},
  year={2021},
  publisher={Canonical Ltd.},
  howpublished={\url{https://wiki.apparmor.net/index.php/Main_Page}}
}
@inproceedings{RASP2,
  title={ModSecurity: An Open Source Web Application Firewall},
  author={VanderSchee, Brandon and Costan, Victor and Gupta, Anurag},
  booktitle={Proceedings of the 19th Annual Network and Distributed System Security Symposium},
  pages={29--29},
  year={2012},
  organization={Internet Society}
}
@misc{RASP3,
  title={Sqreen},
  author={Sqreen Technologies S.A.S.},
  year={2021},
  publisher={Sqreen Technologies S.A.S.},
  howpublished={\url{https://www.sqreen.com/}}
}
@misc{RASP4,
  title={Contrast Security},
  author={Contrast Security, Inc.},
  year={2021},
  publisher={Contrast Security, Inc.},
  howpublished={\url{https://www.contrastsecurity.com/}}
}
@misc{RASP5,
  title={Datadome RASP},
  author={Datadome},
  year={2021},
  publisher={Datadome},
  howpublished={\url{https://www.datadome.co/}}
}
@misc{alamar1,
  title={The Illustrated Word2vec},
  author={Alammar, Jay},
  year={2016},
  howpublished = {\url{https://jalammar.github.io/illustrated-word2vec/}}
}
@misc{alamar2,
  title={The Illustrated Transformer},
  author={Alammar, Jay},
  year={2018},
  howpublished = {\url{https://jalammar.github.io/illustrated-transformer/}}
}
@online{nvidia2022graph,
  title={What Are Graph Neural Networks?},
  author={RICK MERRITT},
  year={2022},
  month={October 24},
  url={https://blogs.nvidia.com/blog/2022/10/24/what-are-graph-neural-networks/},
  organization={NVIDIA Blog},
  note={[Blog post]}
}

@misc{birnn,
  title={Bidirectional RNN for Classification},
  author={Easy TensorFlow},
  year={n.d.},
  howpublished = {\url{https://www.easy-tensorflow.com/tf-tutorials/recurrent-neural-networks/bidirectional-rnn-for-classification}}
}

@misc{rnn,
  title={Three Types of Recurrent Neural Networks},
  author={Yujian Tang},
  year={2021},
  month={November 10},
  howpublished = {\url{https://pub.towardsai.net/three-types-of-recurrent-neural-networks-567b4e9c4261}}
}

@incollection{pooling_strat,
  doi = {10.1007/978-3-030-58323-1_23},
  url = {https://doi.org/10.1007/978-3-030-58323-1_23},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {214--221},
  author = {Jan Lehe{\v{c}}ka and Jan {\v{S}}vec and Pavel Ircing and Lubo{\v{s}} {\v{S}}m{\'{\i}}dl},
  title = {Adjusting {BERT}'s Pooling Layer for Large-Scale Multi-Label Text Classification},
  booktitle = {Text,  Speech,  and Dialogue}
}

@misc{GNN_CV,
  doi = {10.48550/ARXIV.2209.13232},
  url = {https://arxiv.org/abs/2209.13232},
  author = {Chen,  Chaoqi and Wu,  Yushuang and Dai,  Qiyuan and Zhou,  Hong-Yu and Xu,  Mutian and Yang,  Sibei and Han,  Xiaoguang and Yu,  Yizhou},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{GNN_Reccomend,
  doi = {10.48550/ARXIV.2011.02260},
  url = {https://arxiv.org/abs/2011.02260},
  author = {Wu,  Shiwen and Sun,  Fei and Zhang,  Wentao and Xie,  Xu and Cui,  Bin},
  keywords = {Information Retrieval (cs.IR),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Graph Neural Networks in Recommender Systems: A Survey},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@misc{GNN_NLP,
  doi = {10.48550/ARXIV.2106.06090},
  url = {https://arxiv.org/abs/2106.06090},
  author = {Wu,  Lingfei and Chen,  Yu and Shen,  Kai and Guo,  Xiaojie and Gao,  Hanning and Li,  Shucheng and Pei,  Jian and Long,  Bo},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Graph Neural Networks for Natural Language Processing: A Survey},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@unknown{Dynamic_embs,
author = {Xu, Chenxin and Wei, Yuxi and Tang, Bohan and Yin, Sheng and Zhang, Ya and Chen, Siheng},
year = {2022},
month = {06},
pages = {},
title = {Dynamic-Group-Aware Networks for Multi-Agent Trajectory Prediction with Relational Reasoning},
doi = {10.48550/arXiv.2206.13114}
}

@misc{positional,
  doi = {10.48550/ARXIV.2102.11090},
  url = {https://arxiv.org/abs/2102.11090},
  author = {Dufter,  Philipp and Schmitt,  Martin and Sch\"{u}tze,  Hinrich},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Position Information in Transformers: An Overview},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{over_smooth,
  doi = {10.48550/ARXIV.2006.13318},
  url = {https://arxiv.org/abs/2006.13318},
  author = {Cai,  Chen and Wang,  Yusu},
  keywords = {Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {A Note on Over-Smoothing for Graph Neural Networks},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{over_squash,
  doi = {10.48550/ARXIV.2111.14522},
  url = {https://arxiv.org/abs/2111.14522},
  author = {Topping,  Jake and Di Giovanni,  Francesco and Chamberlain,  Benjamin Paul and Dong,  Xiaowen and Bronstein,  Michael M.},
  keywords = {Machine Learning (stat.ML),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Understanding over-squashing and bottlenecks on graphs via curvature},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{devopedia_roc,
  title={ROC Curve},
  year={2019},
  howpublished = {\url{https://devopedia.org/roc-curve}}
}

@article{zhou2023codeBERTscore,
  url = {https://arxiv.org/abs/2302.05527},
  author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},
  title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},  
  publisher = {arXiv},
  year = {2023},
}

@article{husain_codesearchnet_2019,
    title = {{CodeSearchNet} {Challenge}: {Evaluating} the {State} of {Semantic} {Code} {Search}},
    shorttitle = {{CodeSearchNet} {Challenge}},
    url = {http://arxiv.org/abs/1909.09436},
    urldate = {2020-03-12},
    journal = {arXiv:1909.09436 [cs, stat]},
    author = {Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},
    month = sep,
    year = {2019},
    note = {arXiv: 1909.09436},
}

@article{graphormer,
  doi = {10.48550/ARXIV.2106.05234},
  url = {https://arxiv.org/abs/2106.05234},
  author = {Ying,  Chengxuan and Cai,  Tianle and Luo,  Shengjie and Zheng,  Shuxin and Ke,  Guolin and He,  Di and Shen,  Yanming and Liu,  Tie-Yan},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Do Transformers Really Perform Bad for Graph Representation?},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{tokengt,
  doi = {10.48550/ARXIV.2207.02505},
  url = {https://arxiv.org/abs/2207.02505},
  author = {Kim,  Jinwoo and Nguyen,  Tien Dat and Min,  Seonwoo and Cho,  Sungjun and Lee,  Moontae and Lee,  Honglak and Hong,  Seunghoon},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Pure Transformers are Powerful Graph Learners},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{EGT,
  doi = {10.48550/ARXIV.2108.03348},
  url = {https://arxiv.org/abs/2108.03348},
  author = {Hussain,  Md Shamim and Zaki,  Mohammed J. and Subramanian,  Dharmashankar},
  keywords = {Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Global Self-Attention as a Replacement for Graph Convolution},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{GRPE,
  doi = {10.48550/ARXIV.2201.12787},
  url = {https://arxiv.org/abs/2201.12787},
  author = {Park,  Wonpyo and Chang,  Woonggi and Lee,  Donggeon and Kim,  Juntae and Hwang,  Seung-won},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {GRPE: Relative Positional Encoding for Graph Transformer},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{spectral,
  doi = {10.48550/ARXIV.2106.03893},
  url = {https://arxiv.org/abs/2106.03893},
  author = {Kreuzer,  Devin and Beaini,  Dominique and Hamilton,  William L. and Létourneau,  Vincent and Tossou,  Prudencio},
  keywords = {Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Rethinking Graph Transformers with Spectral Attention},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@misc{graph_trans,
  doi = {10.48550/ARXIV.1911.07470},
  url = {https://arxiv.org/abs/1911.07470},
  author = {Cai,  Deng and Lam,  Wai},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Graph Transformer for Graph-to-Sequence Learning},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{alBERT,
  doi = {10.48550/ARXIV.1909.11942},
  url = {https://arxiv.org/abs/1909.11942},
  author = {Lan,  Zhenzhong and Chen,  Mingda and Goodman,  Sebastian and Gimpel,  Kevin and Sharma,  Piyush and Soricut,  Radu},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{distilBERT,
  doi = {10.48550/ARXIV.1910.01108},
  url = {https://arxiv.org/abs/1910.01108},
  author = {Sanh,  Victor and Debut,  Lysandre and Chaumond,  Julien and Wolf,  Thomas},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {DistilBERT,  a distilled version of BERT: smaller,  faster,  cheaper and lighter},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{longformer,
  doi = {10.48550/ARXIV.2004.05150},
  url = {https://arxiv.org/abs/2004.05150},
  author = {Beltagy,  Iz and Peters,  Matthew E. and Cohan,  Arman},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Longformer: The Long-Document Transformer},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{reformer,
  doi = {10.48550/ARXIV.2001.04451},
  url = {https://arxiv.org/abs/2001.04451},
  author = {Kitaev,  Nikita and Kaiser,  Łukasz and Levskaya,  Anselm},
  keywords = {Machine Learning (cs.LG),  Computation and Language (cs.CL),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Reformer: The Efficient Transformer},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{xlnet,
  doi = {10.48550/ARXIV.1906.08237},
  url = {https://arxiv.org/abs/1906.08237},
  author = {Yang,  Zhilin and Dai,  Zihang and Yang,  Yiming and Carbonell,  Jaime and Salakhutdinov,  Ruslan and Le,  Quoc V.},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{constrastive_learn,
  doi = {10.48550/ARXIV.2011.00362},
  url = {https://arxiv.org/abs/2011.00362},
  author = {Jaiswal,  Ashish and Babu,  Ashwin Ramesh and Zadeh,  Mohammad Zaki and Banerjee,  Debapriya and Makedon,  Fillia},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {A Survey on Contrastive Self-supervised Learning},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{word_embs,
  author = {Ruder, Sebastian},
  title = {Word embeddings 1: Introduction to word embeddings},
  year = {2016},
  howpublished = {\url{https://www.ruder.io/word-embeddings-1/}},
  note = {Accessed March 9, 2023}
}
@misc{BERT_insignt,
  doi = {10.48550/ARXIV.1906.04341},
  url = {https://arxiv.org/abs/1906.04341},
  author = {Clark,  Kevin and Khandelwal,  Urvashi and Levy,  Omer and Manning,  Christopher D.},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {What Does BERT Look At? An Analysis of BERT's Attention},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{BERTviz,
    title = "A Multiscale Visualization of Attention in the Transformer Model",
    author = "Vig, Jesse",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-3007",
    doi = "10.18653/v1/P19-3007",
    pages = "37--42",
}